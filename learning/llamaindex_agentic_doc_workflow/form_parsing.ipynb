{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex\n",
    "    , StorageContext\n",
    "    , load_index_from_storage\n",
    ")\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent\n",
    "    , StopEvent\n",
    "    , Workflow\n",
    "    , step\n",
    "    , Event\n",
    "    , Context\n",
    ")\n",
    "from helper import get_llama_cloud_api_key, get_llama_cloud_base_url, extract_html_content\n",
    "from IPython.display import display, HTML\n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_cloud_api_key = get_llama_cloud_api_key()\n",
    "llama_cloud_base_url = get_llama_cloud_base_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: content_guideline_instruction is deprecated and may be remove in a future release. Use system_prompt, system_prompt_append or user_prompt instead.\n",
      "WARNING: formatting_instruction is deprecated and may be remove in a future release. Use system_prompt, system_prompt_append or user_prompt instead.\n",
      "Started parsing the file under job_id 158f0f4a-a1ec-40d6-83da-750b5a2ee94f\n"
     ]
    }
   ],
   "source": [
    "parser = LlamaParse(\n",
    "    api_key=llama_cloud_api_key\n",
    "    , base_url=llama_cloud_base_url\n",
    "    , result_type=\"markdown\"\n",
    "    , content_guideline_instruction=\"This is a job application form. Create a list of all the fields that need to be filled in.\"\n",
    "    , formatting_instruction=\"Return a bulleted list of the fields ONLY.\"\n",
    ")\n",
    "result = parser.load_data(\"data/fake_application_form.pdf\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 60bda80e-cc6e-4b32-894a-c67b44a8ceb7\n",
      "Text: # Big Tech Co. Job Application Form  # Position: Senior Web\n",
      "Developer C3  Thanks for applying to Big Tech Co.! We are humbled that\n",
      "you would consider working here.  Please fill in the following form to\n",
      "help us get started.  |First Name|Last Name| |---|---| |Email|Phone|\n",
      "|Linkedin|Project Portfolio| |Degree|Graduation Date| |Current Job\n",
      "title|Cur...\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Big Tech Co. Job Application Form\n",
      "\n",
      "# Position: Senior Web Developer C3\n",
      "\n",
      "Thanks for applying to Big Tech Co.! We are humbled that you would consider working here.\n",
      "\n",
      "Please fill in the following form to help us get started.\n",
      "\n",
      "|First Name|Last Name|\n",
      "|---|---|\n",
      "|Email|Phone|\n",
      "|Linkedin|Project Portfolio|\n",
      "|Degree|Graduation Date|\n",
      "|Current Job title|Current Employer|\n",
      "|Technical Skills|Technical Skills|\n",
      "|Describe why you’re a good fit for this position|Describe why you’re a good fit for this position|\n",
      "|Do you have 5 years of experience in React?|Do you have 5 years of experience in React?|\n"
     ]
    }
   ],
   "source": [
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3.2:1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_json = llm.complete(\n",
    "    f\"\"\"\n",
    "    This is a parsed form.\n",
    "    Convert it into a JSON object containing only the list \n",
    "    of fields to be filled in, in the form {{ fields: [...] }}. \n",
    "    <form>{result.text}</form>. \n",
    "    Return JSON ONLY, no markdown.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{ \"fields\": [\"First Name\", \"Last Name\", \"Email\", \"Phone\", \"Linkedin\", \"Degree\", \"Graduation Date\", \"Current Job title\", \"Technical Skills\", \"Describe why you’re a good fit for this position\", \"Do you have 5 years of experience in React?\" ] }'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_json.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Name',\n",
       " 'Last Name',\n",
       " 'Email',\n",
       " 'Phone',\n",
       " 'Linkedin',\n",
       " 'Degree',\n",
       " 'Graduation Date',\n",
       " 'Current Job title',\n",
       " 'Technical Skills',\n",
       " 'Describe why you’re a good fit for this position',\n",
       " 'Do you have 5 years of experience in React?']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = json.loads(raw_json.text)[\"fields\"]\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseFormEvent(Event):\n",
    "    application_form: str\n",
    "\n",
    "class QueryEvent(Event):\n",
    "    query: str\n",
    "    field: str \n",
    "\n",
    "class ResponseEvent(Event):\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGWorkflow(Workflow):\n",
    "    storage_dir = \"./storage\"\n",
    "    llm: Ollama\n",
    "    query_engine: VectorStoreIndex\n",
    "    embed_model: OllamaEmbedding\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"Resume file is required\")\n",
    "        \n",
    "        # define LLM\n",
    "        self.llm = Ollama(model=\"llama3.2:3b\")\n",
    "        self.embed_model=OllamaEmbedding(model_name=\"nomic-embed-text\")\n",
    "\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context, embed_model=self.embed_model)\n",
    "        else:\n",
    "            documents = LlamaParse(\n",
    "                result_type=\"markdown\"\n",
    "                , content_guideline_instruction=\"This is a resume, gather related facts together and format it as bullet points with headers\"\n",
    "            ).load_data(ev.resume_file)\n",
    "\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents=documents\n",
    "                , embed_model=self.embed_model\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "        \n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "    \n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev:ParseFormEvent) -> QueryEvent:\n",
    "        parser = LlamaParse(\n",
    "            api_key=llama_cloud_api_key\n",
    "            , base_url=llama_cloud_base_url\n",
    "            , result_type=\"markdown\"\n",
    "            , content_guideline_instruction=\"This is a job application form. Create a list of all the fields that need to be filled in.\"\n",
    "            , formatting_instruction=\"Return a bulleted list of the fields ONLY.\"\n",
    "        )\n",
    "\n",
    "        result = parser.load_data(ev.application_form)[0]\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"\"\"\n",
    "            This is a parsed form.\n",
    "            Convert it into a JSON object containing only the list \n",
    "            of fields to be filled in, in the form {{ fields: [...] }}. \n",
    "            <form>{result.text}</form>.\n",
    "            Return JSON ONLY, no markdown.\"\"\"\n",
    "        )\n",
    "        print(raw_json)\n",
    "        fields = json.loads(raw_json.text)[\"fields\"]\n",
    "        print(f\"fields: {fields}\")\n",
    "\n",
    "        for field in fields:\n",
    "            ctx.send_event(\n",
    "                QueryEvent(\n",
    "                    field=field\n",
    "                    , query=f\"How would you answer this question about the candidate? {field}\"\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        await ctx.set(\"total_fields\", len(fields))\n",
    "        return\n",
    "\n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> ResponseEvent:\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "        return ResponseEvent(field=ev.field, response=response.response)\n",
    "    \n",
    "    @step\n",
    "    async def fill_in_application(self, ctx: Context, ev: ResponseEvent) -> StopEvent:\n",
    "        total_fields = await ctx.get(\"total_fields\")\n",
    "\n",
    "        responses = ctx.collect_events(ev, [ResponseEvent] * total_fields, timeout=3000)\n",
    "        if responses is None:\n",
    "            return None \n",
    "        \n",
    "        responseListString = \"\\n\".join(\"Field: \" + r.field + \"\\n\" + \"Response: \" + r.response for r in responses)\n",
    "\n",
    "        result = self.llm.complete(\n",
    "            f\"\"\"\n",
    "            You are given a list of fields in an application form and responses to\n",
    "            questions about those fields from a resume. Combine the two into a list of\n",
    "            fields and succinct, factual answers to fill in those fields.\n",
    "\n",
    "            <responses>\n",
    "            {responseListString}\n",
    "            </responses>\n",
    "            \"\"\"\n",
    "        )\n",
    "        return StopEvent(result=result)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = RAGWorkflow(verbose=False, timeout=3000)\n",
    "result = await w.run(\n",
    "    resume_file=\"data/fake_resume.pdf\"\n",
    "    , application_form=\"data/fake_application_form.pdf\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKFLOW_FILE = \"workflows/form_parsing_workflow.html\"\n",
    "draw_all_possible_flows(w, filename=WORKFLOW_FILE)\n",
    "html_content = extract_html_content(WORKFLOW_FILE)\n",
    "display(HTML(html_content), metadata=dict(isolated=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
